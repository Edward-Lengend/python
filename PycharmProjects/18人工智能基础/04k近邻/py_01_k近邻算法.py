from sklearn.neighbors import KNeighborsClassifier

# 欧式距离

# 特征值
x = [ [179, 42], [178, 43], [165,36], [177,42], [160,35]]
# 目标值
y = ["男", "男", "女", "男", "女"]

# x = [[0], [1], [2], [3]]
# y = [0, 0, 1, 1]

# 机器学习
#实例化一个训练模型                           # k值
estimator = KNeighborsClassifier(n_neighbors=3)
# 使用fit方法进行训练
estimator.fit(x, y)

# 预测其他值            # 测试集均为男性
ret = estimator.predict([[173, 42], [170, 40], [167, 43]])
print(ret)

# 很容易看到第一维身高特征是第二维脚码特征的4倍左右，
# 那么在进行距离度量的时候，我们就会偏向于第一维特征。、
# 这样造成俩个特征并不是等价重要的，最终可能会导致距离计算错误，从而导致预测错误。
# 一个女性的脚43码的可能性，远远小于男性脚43码的可能性，
# 那么为什么算法还是会预测F为女性呢？那是因为由于各个特征量纲的不同，
# 在这里导致了身高的重要性已经远远大于脚码了，这是不客观的。
# 所以我们应该让每个特征都是同等重要的！这也是我们要归一化的原因!